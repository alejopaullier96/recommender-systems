{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www3.um.edu.uy/logoum.jpg\" width=300>\n",
    "<h1 align=\"center\">Thesis - HPF MRR</h1> \n",
    "<h2 align=\"center\">Alejo Paullier</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lkpy.lenskit.org/en/stable/knn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit import batch, topn, util\n",
    "from lenskit import crossfold as xf\n",
    "from lenskit.algorithms import Recommender\n",
    "from lenskit.algorithms.hpf import HPF as hpfl\n",
    "from hpfrec import HPF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK\n",
    "\n",
    "ratings = pd.read_csv('C:\\\\Users\\\\Alejo\\\\Tesis\\\\Demo\\\\ml-100k\\\\u.data', sep='\\t',\n",
    "                      names=['user', 'item', 'rating', 'timestamp'])\n",
    "\n",
    "\n",
    "def eval(aname, algo, train, test):\n",
    "    fittable = util.clone(algo) # Object cloning means to create an exact copy of the original object.\n",
    "    fittable = Recommender.adapt(fittable) \n",
    "    fittable.fit(train) # Entrenamos el algoritmo con el training dataset\n",
    "    users = test.user.unique() # Devuelve un array con los users unicos en el testing dataset\n",
    "    # now we run the recommender\n",
    "    recs = batch.recommend(fittable, users, 100)\n",
    "    # add the algorithm name for analyzability\n",
    "    recs['Algorithm'] = aname\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainer(features):\n",
    "    all_recs = []\n",
    "    test_data = []\n",
    "    features=int(features)\n",
    "    \n",
    "    hpf = hpfl(features,verbose=False) # define algorithm\n",
    "    \n",
    "    for train, test in xf.partition_users(ratings[['user', 'item', 'rating']], 5, xf.SampleFrac(0.2)):\n",
    "        test_data.append(test) # save testing data\n",
    "        all_recs.append(eval('HPF', hpf, train, test))\n",
    "    all_recs = pd.concat(all_recs, ignore_index=True)\n",
    "    test_data = pd.concat(test_data, ignore_index=True)\n",
    "    rla = topn.RecListAnalysis()\n",
    "    rla.add_metric(topn.recip_rank)\n",
    "    results = rla.compute(all_recs, test_data)\n",
    "                          \n",
    "    return results[\"recip_rank\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************                                                                                     \n",
      "Hierarchical Poisson Factorization                                                                                     \n",
      "**********************************                                                                                     \n",
      "Number of users: 943                                                                                                   \n",
      "Number of items: 1680                                                                                                  \n",
      "Latent factors to use: 79                                                                                              \n",
      "Initializing parameters...                                                                                             \n",
      "Allocating Phi matrix...                                                                                               \n",
      "Initializing optimization procedure...                                                                                 \n",
      "Iteration 10 | train llk: -340768 | train rmse: 2.5847                                                                 \n",
      "Iteration 20 | train llk: -282286 | train rmse: 2.4277                                                                 \n",
      "Iteration 30 | train llk: -264164 | train rmse: 2.3709                                                                 \n",
      "Iteration 40 | train llk: -255968 | train rmse: 2.3446                                                                 \n",
      "Iteration 50 | train llk: -251099 | train rmse: 2.3291                                                                 \n",
      "Iteration 60 | train llk: -247751 | train rmse: 2.3179                                                                 \n",
      "Iteration 70 | train llk: -245277 | train rmse: 2.3094                                                                 \n",
      "Iteration 80 | train llk: -243485 | train rmse: 2.3037                                                                 \n",
      "Iteration 90 | train llk: -242138 | train rmse: 2.2991                                                                 \n",
      "Iteration 100 | train llk: -241104 | train rmse: 2.2961                                                                \n",
      "                                                                                                                       \n",
      "\n",
      "Optimization finished\n",
      "Final log-likelihood: -241104                                                                                          \n",
      "Final RMSE: 2.2961                                                                                                     \n",
      "Minutes taken (optimization part): 0.3                                                                                 \n",
      "**********************************                                                                                     \n",
      "Hierarchical Poisson Factorization                                                                                     \n",
      "**********************************                                                                                     \n",
      "Number of users: 943                                                                                                   \n",
      "Number of items: 1671                                                                                                  \n",
      "Latent factors to use: 79                                                                                              \n",
      "Initializing parameters...                                                                                             \n",
      "Allocating Phi matrix...                                                                                               \n",
      "Initializing optimization procedure...                                                                                 \n",
      "Iteration 10 | train llk: -333617 | train rmse: 2.5672                                                                 \n",
      "Iteration 20 | train llk: -280000 | train rmse: 2.4210                                                                 \n",
      "Iteration 30 | train llk: -262997 | train rmse: 2.3705                                                                 \n",
      "Iteration 40 | train llk: -254938 | train rmse: 2.3469                                                                 \n",
      "Iteration 50 | train llk: -250197 | train rmse: 2.3324                                                                 \n",
      "Iteration 60 | train llk: -246990 | train rmse: 2.3213                                                                 \n",
      "Iteration 70 | train llk: -244758 | train rmse: 2.3137                                                                 \n",
      "Iteration 80 | train llk: -243053 | train rmse: 2.3082                                                                 \n",
      "Iteration 90 | train llk: -241798 | train rmse: 2.3040                                                                 \n",
      "Iteration 100 | train llk: -240644 | train rmse: 2.3002                                                                \n",
      "                                                                                                                       \n",
      "\n",
      "Optimization finished\n",
      "Final log-likelihood: -240644                                                                                          \n",
      "Final RMSE: 2.3002                                                                                                     \n",
      "Minutes taken (optimization part): 0.3                                                                                 \n",
      "**********************************                                                                                     \n",
      "Hierarchical Poisson Factorization                                                                                     \n",
      "**********************************                                                                                     \n",
      "Number of users: 943                                                                                                   \n",
      "Number of items: 1679                                                                                                  \n",
      "Latent factors to use: 79                                                                                              \n",
      "Initializing parameters...                                                                                             \n",
      "Allocating Phi matrix...                                                                                               \n",
      "Initializing optimization procedure...                                                                                 \n",
      "Iteration 10 | train llk: -337917 | train rmse: 2.5829                                                                 \n",
      "Iteration 20 | train llk: -281706 | train rmse: 2.4316                                                                 \n",
      "Iteration 30 | train llk: -264864 | train rmse: 2.3795                                                                 \n",
      "Iteration 40 | train llk: -257608 | train rmse: 2.3563                                                                 \n",
      "Iteration 50 | train llk: -253605 | train rmse: 2.3443                                                                 \n",
      "Iteration 60 | train llk: -250872 | train rmse: 2.3356                                                                 \n",
      "Iteration 70 | train llk: -249017 | train rmse: 2.3296                                                                 \n",
      "Iteration 80 | train llk: -247528 | train rmse: 2.3240                                                                 \n",
      "Iteration 90 | train llk: -246318 | train rmse: 2.3193                                                                 \n",
      "Iteration 100 | train llk: -245316 | train rmse: 2.3156                                                                \n",
      "                                                                                                                       \n",
      "\n",
      "Optimization finished\n",
      "Final log-likelihood: -245316                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE: 2.3156                                                                                                     \n",
      "Minutes taken (optimization part): 0.3                                                                                 \n",
      "**********************************                                                                                     \n",
      "Hierarchical Poisson Factorization                                                                                     \n",
      "**********************************                                                                                     \n",
      "Number of users: 943                                                                                                   \n",
      "Number of items: 1677                                                                                                  \n",
      "Latent factors to use: 79                                                                                              \n",
      "Initializing parameters...                                                                                             \n",
      "Allocating Phi matrix...                                                                                               \n",
      "Initializing optimization procedure...                                                                                 \n",
      "Iteration 10 | train llk: -344388 | train rmse: 2.5968                                                                 \n",
      "Iteration 20 | train llk: -283724 | train rmse: 2.4342                                                                 \n",
      "Iteration 30 | train llk: -265502 | train rmse: 2.3771                                                                 \n",
      "Iteration 40 | train llk: -257781 | train rmse: 2.3535                                                                 \n",
      "Iteration 50 | train llk: -253575 | train rmse: 2.3418                                                                 \n",
      "Iteration 60 | train llk: -250600 | train rmse: 2.3336                                                                 \n",
      "Iteration 70 | train llk: -248626 | train rmse: 2.3279                                                                 \n",
      "Iteration 80 | train llk: -247004 | train rmse: 2.3238                                                                 \n",
      "Iteration 90 | train llk: -245617 | train rmse: 2.3196                                                                 \n",
      "Iteration 100 | train llk: -244441 | train rmse: 2.3156                                                                \n",
      "                                                                                                                       \n",
      "\n",
      "Optimization finished\n",
      "Final log-likelihood: -244441                                                                                          \n",
      "Final RMSE: 2.3156                                                                                                     \n",
      "Minutes taken (optimization part): 0.3                                                                                 \n",
      "**********************************                                                                                     \n",
      "Hierarchical Poisson Factorization                                                                                     \n",
      "**********************************                                                                                     \n",
      "Number of users: 943                                                                                                   \n",
      "Number of items: 1677                                                                                                  \n",
      "Latent factors to use: 79                                                                                              \n",
      "Initializing parameters...                                                                                             \n",
      "Allocating Phi matrix...                                                                                               \n",
      "Initializing optimization procedure...                                                                                 \n",
      "Iteration 10 | train llk: -340208 | train rmse: 2.5857                                                                 \n",
      "Iteration 20 | train llk: -281930 | train rmse: 2.4299                                                                 \n",
      "Iteration 30 | train llk: -264326 | train rmse: 2.3726                                                                 \n",
      "Iteration 40 | train llk: -256066 | train rmse: 2.3460                                                                 \n",
      "Iteration 50 | train llk: -251183 | train rmse: 2.3303                                                                 \n",
      "Iteration 60 | train llk: -247903 | train rmse: 2.3204                                                                 \n",
      "Iteration 70 | train llk: -245592 | train rmse: 2.3144                                                                 \n",
      "Iteration 80 | train llk: -243998 | train rmse: 2.3100                                                                 \n",
      "Iteration 90 | train llk: -242852 | train rmse: 2.3065                                                                 \n",
      "Iteration 100 | train llk: -242007 | train rmse: 2.3041                                                                \n",
      "                                                                                                                       \n",
      "\n",
      "Optimization finished\n",
      "Final log-likelihood: -242007                                                                                          \n",
      "Final RMSE: 2.3041                                                                                                     \n",
      "Minutes taken (optimization part): 0.3                                                                                 \n",
      "**********************************                                                                                     \n",
      "Hierarchical Poisson Factorization                                                                                     \n",
      "**********************************                                                                                     \n",
      "Number of users: 943                                                                                                   \n",
      "Number of items: 1670                                                                                                  \n",
      "Latent factors to use: 46                                                                                              \n",
      "Initializing parameters...                                                                                             \n",
      "Allocating Phi matrix...                                                                                               \n",
      "Initializing optimization procedure...                                                                                 \n",
      "Iteration 10 | train llk: -356249 | train rmse: 2.6197                                                                 \n",
      "Iteration 20 | train llk: -294133 | train rmse: 2.4643                                                                 \n",
      "Iteration 30 | train llk: -276839 | train rmse: 2.4112                                                                 \n",
      "Iteration 40 | train llk: -269038 | train rmse: 2.3852                                                                 \n",
      "Iteration 50 | train llk: -264656 | train rmse: 2.3712                                                                 \n",
      "Iteration 60 | train llk: -261885 | train rmse: 2.3623                                                                 \n",
      "Iteration 70 | train llk: -259815 | train rmse: 2.3558                                                                 \n",
      "Iteration 80 | train llk: -258337 | train rmse: 2.3503                                                                 \n",
      "Iteration 90 | train llk: -257207 | train rmse: 2.3463                                                                 \n",
      "Iteration 100 | train llk: -256317 | train rmse: 2.3432                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \n",
      "\n",
      "Optimization finished\n",
      "Final log-likelihood: -256317                                                                                          \n",
      "Final RMSE: 2.3432                                                                                                     \n",
      "Minutes taken (optimization part): 0.2                                                                                 \n",
      "**********************************                                                                                     \n",
      "Hierarchical Poisson Factorization                                                                                     \n",
      "**********************************                                                                                     \n",
      "Number of users: 943                                                                                                   \n",
      "Number of items: 1679                                                                                                  \n",
      "Latent factors to use: 46                                                                                              \n",
      "Initializing parameters...                                                                                             \n",
      "Allocating Phi matrix...                                                                                               \n",
      "Initializing optimization procedure...                                                                                 \n",
      "Iteration 10 | train llk: -357551 | train rmse: 2.6316                                                                 \n",
      "Iteration 20 | train llk: -298075 | train rmse: 2.4786                                                                 \n",
      "Iteration 30 | train llk: -280717 | train rmse: 2.4234                                                                 \n",
      "Iteration 40 | train llk: -272695 | train rmse: 2.3978                                                                 \n",
      "Iteration 50 | train llk: -268114 | train rmse: 2.3827                                                                 \n",
      "Iteration 60 | train llk: -265174 | train rmse: 2.3740                                                                 \n",
      "Iteration 70 | train llk: -263428 | train rmse: 2.3685                                                                 \n",
      "Iteration 80 | train llk: -262193 | train rmse: 2.3648                                                                 \n",
      "Iteration 90 | train llk: -261165 | train rmse: 2.3614                                                                 \n",
      "Iteration 100 | train llk: -260329 | train rmse: 2.3585                                                                \n",
      "                                                                                                                       \n",
      "\n",
      "Optimization finished\n",
      "Final log-likelihood: -260329                                                                                          \n",
      "Final RMSE: 2.3585                                                                                                     \n",
      "Minutes taken (optimization part): 0.2                                                                                 \n",
      "**********************************                                                                                     \n",
      "Hierarchical Poisson Factorization                                                                                     \n",
      "**********************************                                                                                     \n",
      "Number of users: 943                                                                                                   \n",
      "Number of items: 1677                                                                                                  \n",
      "Latent factors to use: 46                                                                                              \n",
      "Initializing parameters...                                                                                             \n",
      "Allocating Phi matrix...                                                                                               \n",
      "Initializing optimization procedure...                                                                                 \n",
      "Iteration 10 | train llk: -362019 | train rmse: 2.6355                                                                 \n",
      "Iteration 20 | train llk: -296598 | train rmse: 2.4723                                                                 \n",
      "Iteration 30 | train llk: -276860 | train rmse: 2.4088                                                                 \n",
      "Iteration 40 | train llk: -268566 | train rmse: 2.3808                                                                 \n",
      "Iteration 50 | train llk: -263994 | train rmse: 2.3648                                                                 \n",
      "Iteration 60 | train llk: -261107 | train rmse: 2.3555                                                                 \n",
      "Iteration 70 | train llk: -259156 | train rmse: 2.3491                                                                 \n",
      "Iteration 80 | train llk: -257611 | train rmse: 2.3442                                                                 \n",
      "Iteration 90 | train llk: -256407 | train rmse: 2.3404                                                                 \n",
      "Iteration 100 | train llk: -255531 | train rmse: 2.3375                                                                \n",
      "                                                                                                                       \n",
      "\n",
      "Optimization finished\n",
      "Final log-likelihood: -255531                                                                                          \n",
      "Final RMSE: 2.3375                                                                                                     \n",
      "Minutes taken (optimization part): 0.2                                                                                 \n",
      "**********************************                                                                                     \n",
      "Hierarchical Poisson Factorization                                                                                     \n",
      "**********************************                                                                                     \n",
      "Number of users: 943                                                                                                   \n",
      "Number of items: 1680                                                                                                  \n",
      "Latent factors to use: 46                                                                                              \n",
      "Initializing parameters...                                                                                             \n",
      "Allocating Phi matrix...                                                                                               \n",
      "Initializing optimization procedure...                                                                                 \n",
      "Iteration 10 | train llk: -360151 | train rmse: 2.6335                                                                 \n",
      "Iteration 20 | train llk: -300076 | train rmse: 2.4802                                                                 \n",
      "Iteration 30 | train llk: -281546 | train rmse: 2.4231                                                                 \n",
      "Iteration 40 | train llk: -273130 | train rmse: 2.3941                                                                 \n",
      "Iteration 50 | train llk: -268344 | train rmse: 2.3779                                                                 \n",
      "Iteration 60 | train llk: -265434 | train rmse: 2.3683                                                                 \n",
      "Iteration 70 | train llk: -263529 | train rmse: 2.3619                                                                 \n",
      "Iteration 80 | train llk: -262185 | train rmse: 2.3578                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 90 | train llk: -261124 | train rmse: 2.3547                                                                 \n",
      "Iteration 100 | train llk: -260287 | train rmse: 2.3524                                                                \n",
      "                                                                                                                       \n",
      "\n",
      "Optimization finished\n",
      "Final log-likelihood: -260287                                                                                          \n",
      "Final RMSE: 2.3524                                                                                                     \n",
      "Minutes taken (optimization part): 0.2                                                                                 \n",
      "**********************************                                                                                     \n",
      "Hierarchical Poisson Factorization                                                                                     \n",
      "**********************************                                                                                     \n",
      "Number of users: 943                                                                                                   \n",
      "Number of items: 1681                                                                                                  \n",
      "Latent factors to use: 46                                                                                              \n",
      "Initializing parameters...                                                                                             \n",
      "Allocating Phi matrix...                                                                                               \n",
      "Initializing optimization procedure...                                                                                 \n",
      "Iteration 10 | train llk: -358673 | train rmse: 2.6279                                                                 \n",
      "Iteration 20 | train llk: -297704 | train rmse: 2.4779                                                                 \n",
      "Iteration 30 | train llk: -279293 | train rmse: 2.4204                                                                 \n",
      "Iteration 40 | train llk: -269679 | train rmse: 2.3861                                                                 \n",
      "Iteration 50 | train llk: -264202 | train rmse: 2.3669                                                                 \n",
      "Iteration 60 | train llk: -260607 | train rmse: 2.3545                                                                 \n",
      "Iteration 70 | train llk: -258490 | train rmse: 2.3473                                                                 \n",
      "Iteration 80 | train llk: -256913 | train rmse: 2.3420                                                                 \n",
      "Iteration 90 | train llk: -255728 | train rmse: 2.3378                                                                 \n",
      "Iteration 100 | train llk: -254796 | train rmse: 2.3344                                                                \n",
      "                                                                                                                       \n",
      "\n",
      "Optimization finished\n",
      "Final log-likelihood: -254796                                                                                          \n",
      "Final RMSE: 2.3344                                                                                                     \n",
      "Minutes taken (optimization part): 0.2                                                                                 \n",
      "**********************************                                                                                     \n",
      "Hierarchical Poisson Factorization                                                                                     \n",
      "**********************************                                                                                     \n",
      "Number of users: 943                                                                                                   \n",
      "Number of items: 1681                                                                                                  \n",
      "Latent factors to use: 29                                                                                              \n",
      "Initializing parameters...                                                                                             \n",
      "Allocating Phi matrix...                                                                                               \n",
      "Initializing optimization procedure...                                                                                 \n",
      "Iteration 10 | train llk: -375784 | train rmse: 2.6660                                                                 \n",
      "Iteration 20 | train llk: -315620 | train rmse: 2.5202                                                                 \n",
      "Iteration 30 | train llk: -294371 | train rmse: 2.4567                                                                 \n",
      "Iteration 40 | train llk: -284228 | train rmse: 2.4249                                                                 \n",
      "Iteration 50 | train llk: -278253 | train rmse: 2.4052                                                                 \n",
      "Iteration 60 | train llk: -274585 | train rmse: 2.3939                                                                 \n",
      "Iteration 70 | train llk: -272239 | train rmse: 2.3874                                                                 \n",
      "Iteration 80 | train llk: -270673 | train rmse: 2.3835                                                                 \n",
      "Iteration 90 | train llk: -269496 | train rmse: 2.3804                                                                 \n",
      "Iteration 100 | train llk: -268502 | train rmse: 2.3773                                                                \n",
      "                                                                                                                       \n",
      "\n",
      "Optimization finished\n",
      "Final log-likelihood: -268502                                                                                          \n",
      "Final RMSE: 2.3773                                                                                                     \n",
      "Minutes taken (optimization part): 0.1                                                                                 \n",
      "**********************************                                                                                     \n",
      "Hierarchical Poisson Factorization                                                                                     \n",
      "**********************************                                                                                     \n",
      "Number of users: 943                                                                                                   \n",
      "Number of items: 1676                                                                                                  \n",
      "Latent factors to use: 29                                                                                              \n",
      "Initializing parameters...                                                                                             \n",
      "Allocating Phi matrix...                                                                                               \n",
      "Initializing optimization procedure...                                                                                 \n",
      "Iteration 10 | train llk: -371620 | train rmse: 2.6555                                                                 \n",
      "Iteration 20 | train llk: -310703 | train rmse: 2.5129                                                                 \n",
      "Iteration 30 | train llk: -292827 | train rmse: 2.4592                                                                 \n",
      "Iteration 40 | train llk: -284528 | train rmse: 2.4325                                                                 \n",
      "Iteration 50 | train llk: -279867 | train rmse: 2.4179                                                                 \n",
      "Iteration 60 | train llk: -276750 | train rmse: 2.4081                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 70 | train llk: -274545 | train rmse: 2.4012                                                                 \n",
      "Iteration 80 | train llk: -272990 | train rmse: 2.3963                                                                 \n",
      "Iteration 90 | train llk: -271943 | train rmse: 2.3930                                                                 \n",
      "Iteration 100 | train llk: -271153 | train rmse: 2.3904                                                                \n",
      "                                                                                                                       \n",
      "\n",
      "Optimization finished\n",
      "Final log-likelihood: -271153                                                                                          \n",
      "Final RMSE: 2.3904                                                                                                     \n",
      "Minutes taken (optimization part): 0.1                                                                                 \n",
      "**********************************                                                                                     \n",
      "Hierarchical Poisson Factorization                                                                                     \n",
      "**********************************                                                                                     \n",
      "Number of users: 943                                                                                                   \n",
      "Number of items: 1670                                                                                                  \n",
      "Latent factors to use: 29                                                                                              \n",
      "Initializing parameters...                                                                                             \n",
      "Allocating Phi matrix...                                                                                               \n",
      "Initializing optimization procedure...                                                                                 \n",
      "Iteration 10 | train llk: -371329 | train rmse: 2.6592                                                                 \n",
      "Iteration 20 | train llk: -314617 | train rmse: 2.5202                                                                 \n",
      "Iteration 30 | train llk: -296325 | train rmse: 2.4637                                                                 \n",
      "Iteration 40 | train llk: -287145 | train rmse: 2.4354                                                                 \n",
      "Iteration 50 | train llk: -281589 | train rmse: 2.4185                                                                 \n",
      "Iteration 60 | train llk: -278091 | train rmse: 2.4075                                                                 \n",
      "Iteration 70 | train llk: -275777 | train rmse: 2.4002                                                                 \n",
      "Iteration 80 | train llk: -274193 | train rmse: 2.3953                                                                 \n",
      "Iteration 90 | train llk: -272928 | train rmse: 2.3916                                                                 \n",
      "Iteration 100 | train llk: -271740 | train rmse: 2.3879                                                                \n",
      "                                                                                                                       \n",
      "\n",
      "Optimization finished\n",
      "Final log-likelihood: -271740                                                                                          \n",
      "Final RMSE: 2.3879                                                                                                     \n",
      "Minutes taken (optimization part): 0.1                                                                                 \n",
      "**********************************                                                                                     \n",
      "Hierarchical Poisson Factorization                                                                                     \n",
      "**********************************                                                                                     \n",
      "Number of users: 943                                                                                                   \n",
      "Number of items: 1675                                                                                                  \n",
      "Latent factors to use: 29                                                                                              \n",
      "Initializing parameters...                                                                                             \n",
      "Allocating Phi matrix...                                                                                               \n",
      "Initializing optimization procedure...                                                                                 \n",
      "Iteration 10 | train llk: -376232 | train rmse: 2.6629                                                                 \n",
      "Iteration 20 | train llk: -312863 | train rmse: 2.5096                                                                 \n",
      "Iteration 30 | train llk: -290450 | train rmse: 2.4448                                                                 \n",
      "Iteration 40 | train llk: -281430 | train rmse: 2.4154                                                                 \n",
      "Iteration 50 | train llk: -276564 | train rmse: 2.3992                                                                 \n",
      "Iteration 60 | train llk: -273774 | train rmse: 2.3899                                                                 \n",
      "Iteration 70 | train llk: -272000 | train rmse: 2.3839                                                                 \n",
      "Iteration 80 | train llk: -270714 | train rmse: 2.3803                                                                 \n",
      "Iteration 90 | train llk: -269736 | train rmse: 2.3773                                                                 \n",
      "Iteration 100 | train llk: -268992 | train rmse: 2.3752                                                                \n",
      "                                                                                                                       \n",
      "\n",
      "Optimization finished\n",
      "Final log-likelihood: -268992                                                                                          \n",
      "Final RMSE: 2.3752                                                                                                     \n",
      "Minutes taken (optimization part): 0.1                                                                                 \n",
      "**********************************                                                                                     \n",
      "Hierarchical Poisson Factorization                                                                                     \n",
      "**********************************                                                                                     \n",
      "Number of users: 943                                                                                                   \n",
      "Number of items: 1680                                                                                                  \n",
      "Latent factors to use: 29                                                                                              \n",
      "Initializing parameters...                                                                                             \n",
      "Allocating Phi matrix...                                                                                               \n",
      "Initializing optimization procedure...                                                                                 \n",
      "Iteration 10 | train llk: -378184 | train rmse: 2.6768                                                                 \n",
      "Iteration 20 | train llk: -314053 | train rmse: 2.5170                                                                 \n",
      "Iteration 30 | train llk: -294382 | train rmse: 2.4590                                                                 \n",
      "Iteration 40 | train llk: -285386 | train rmse: 2.4326                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50 | train llk: -280356 | train rmse: 2.4180                                                                 \n",
      "Iteration 60 | train llk: -277346 | train rmse: 2.4082                                                                 \n",
      "Iteration 70 | train llk: -275192 | train rmse: 2.4009                                                                 \n",
      "Iteration 80 | train llk: -273474 | train rmse: 2.3956                                                                 \n",
      "Iteration 90 | train llk: -272024 | train rmse: 2.3909                                                                 \n",
      "Iteration 100 | train llk: -270894 | train rmse: 2.3875                                                                \n",
      "                                                                                                                       \n",
      "\n",
      "Optimization finished\n",
      "Final log-likelihood: -270894                                                                                          \n",
      "Final RMSE: 2.3875                                                                                                     \n",
      "Minutes taken (optimization part): 0.1                                                                                 \n",
      "**********************************                                                                                     \n",
      "Hierarchical Poisson Factorization                                                                                     \n",
      "**********************************                                                                                     \n",
      "Number of users: 943                                                                                                   \n",
      "Number of items: 1680                                                                                                  \n",
      "Latent factors to use: 75                                                                                              \n",
      "Initializing parameters...                                                                                             \n",
      "Allocating Phi matrix...                                                                                               \n",
      "Initializing optimization procedure...                                                                                 \n",
      "Iteration 10 | train llk: -346135 | train rmse: 2.6014                                                                 \n",
      "Iteration 20 | train llk: -285545 | train rmse: 2.4429                                                                 \n",
      "Iteration 30 | train llk: -266761 | train rmse: 2.3830                                                                 \n",
      "  3%|                                              | 3/100 [03:14<1:53:56, 70.48s/it, best loss: -0.6414333683023186]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3d88ad62cd50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Programas\\Anaconda\\Anaconda\\Lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    405\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[0;32m    406\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\Anaconda\\Anaconda\\Lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\Anaconda\\Anaconda\\Lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    225\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                         \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\Anaconda\\Anaconda\\Lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\Anaconda\\Anaconda\\Lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    842\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 844\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-3d88ad62cd50>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mobjective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_trainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'status'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-bde64c208a3f>\u001b[0m in \u001b[0;36mmodel_trainer\u001b[1;34m(features)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition_users\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSampleFrac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# save testing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mall_recs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'HPF'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhpf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mall_recs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_recs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-b5462c740496>\u001b[0m in \u001b[0;36meval\u001b[1;34m(aname, algo, train, test)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mfittable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Object cloning means to create an exact copy of the original object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mfittable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRecommender\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfittable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mfittable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Entrenamos el algoritmo con el training dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0musers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Devuelve un array con los users unicos en el testing dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# now we run the recommender\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\Anaconda\\Anaconda\\Lib\\site-packages\\lenskit\\algorithms\\basic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, ratings, *args, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m                 \u001b[0mAdditional\u001b[0m \u001b[0marguments\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mits\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \"\"\"\n\u001b[1;32m--> 299\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\Anaconda\\Anaconda\\Lib\\site-packages\\lenskit\\algorithms\\hpf.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, ratings)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fitting HPF model with %d features'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mhpf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhpfdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_index_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0musers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\Anaconda\\Anaconda\\Lib\\site-packages\\hpfrec\\__init__.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, counts_df, val_set)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cast_before_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m                 \u001b[1;31m## after terminating optimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\Anaconda\\Anaconda\\Lib\\site-packages\\hpfrec\\__init__.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    634\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCount\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUserId\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mItemId\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m                         \u001b[0mcython_loops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_llk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcython_loops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_all_objs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m                         \u001b[0mcython_loops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malloc_full_phi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m \t\t\t)\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mhpfrec\\cython_loops.pyx\u001b[0m in \u001b[0;36mhpfrec.cython_loops.fit_hpf\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\Anaconda\\Anaconda\\Lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0m\u001b[0;32m     35\u001b[0m          initial=_NoValue):\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "array = []\n",
    "def objective(params):\n",
    "    features = params['features']\n",
    "    metric = model_trainer(features)\n",
    "    array.append([features,metric])\n",
    "    return {'loss': -metric, 'status': STATUS_OK}\n",
    "\n",
    "space={'features': hp.uniform('features', 1, 100)}\n",
    "\n",
    "best = fmin(objective, space, algo=tpe.suggest,max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [[77.55065396777678, 0.6320892829816492],\n",
    " [89.70366296995682, 0.6146566900995533],\n",
    " [31.639933646171322, 0.6544950447529269],\n",
    " [7.043305962495642, 0.5958213221321255],\n",
    " [24.41846172412374, 0.6304705253450288],\n",
    " [76.76481802959346, 0.6205194634864248],\n",
    " [38.906001399798186, 0.623299223867596],\n",
    " [27.09424989372053, 0.6271463707657792],\n",
    " [36.147677934505786, 0.6409786943460749],\n",
    " [97.17160355861982, 0.6227624639846036],\n",
    " [25.180457156488426, 0.6273036461154918],\n",
    " [92.78812802845108, 0.6292593217859433],\n",
    " [67.01749041243802, 0.6311504768469749],\n",
    " [20.65919018720629, 0.631319851065858],\n",
    " [82.16194110307818, 0.6027200909141324],\n",
    " [57.183766974024635, 0.6056956760971015],\n",
    " [17.41116327496534, 0.6422849445171228],\n",
    " [37.56829977982472, 0.6455651468353156],\n",
    " [59.7720382553142, 0.623245229196316],\n",
    " [55.98200796797128, 0.6221120444035015],\n",
    " [40.31000761986902, 0.6321505634316579],\n",
    " [7.1450480426885505, 0.6059793178536264],\n",
    " [42.304488285030295, 0.62654049607271],\n",
    " [47.396799920393605, 0.6375268513045612],\n",
    " [31.83359580821348, 0.6308129094329122],\n",
    " [50.58046224388475, 0.6307565275140682],\n",
    " [12.30076842652846, 0.6192892045448067],\n",
    " [68.58630121106822, 0.6277957236441857],\n",
    " [72.16559883604013, 0.6188705108370138],\n",
    " [23.277849658771917, 0.6383650635267996],\n",
    " [36.637538366201525, 0.6371401116771256],\n",
    " [39.767433754176054, 0.64594980577962],\n",
    " [65.19132413667043, 0.6240352996950216],\n",
    " [50.55268199689872, 0.6221583881348258],\n",
    " [76.32762502732623, 0.6192742486935091],\n",
    " [5.038368542461655, 0.614617453584875],\n",
    " [68.05689240865846, 0.6136959402130484],\n",
    " [27.162682694322985, 0.6404076970406773],\n",
    " [10.692216769675317, 0.6320270947598469],\n",
    " [75.76730092928894, 0.5948785023446462],\n",
    " [24.439846619849266, 0.6480204425025513],\n",
    " [59.604043870077874, 0.6101121987483699],\n",
    " [20.326527331926698, 0.6444938551676446],\n",
    " [66.5934188111337, 0.6198210272860553],\n",
    " [62.13597550996691, 0.6171269349774073],\n",
    " [78.84331805986507, 0.617825260479445],\n",
    " [38.77046761160387, 0.6312140846815908],\n",
    " [30.34425694173914, 0.6355506804424967],\n",
    " [14.043402831240051, 0.6454995140773434],\n",
    " [45.629150898107014, 0.6358097559768161],\n",
    " [85.24149263290262, 0.6168280324936837],\n",
    " [87.69923378708674, 0.6284189421674122],\n",
    " [71.27847593985942, 0.6177545391841074],\n",
    " [25.33522684632587, 0.6471198297733625],\n",
    " [21.47796307972385, 0.6450594877427547],\n",
    " [57.46823449832021, 0.6247185930523442],\n",
    " [11.484677240148107, 0.6034534519078911],\n",
    " [14.119710037354547, 0.6236733620199875],\n",
    " [90.48099653877794, 0.6090952243385073],\n",
    " [29.399502476278325, 0.6215113516814363],\n",
    " [12.129253235109275, 0.6447223245835411],\n",
    " [64.46080361403725, 0.5929009956605883],\n",
    " [30.774196905630085, 0.6303396351094798],\n",
    " [11.09214389344497, 0.6321786805415233],\n",
    " [78.84697870268235, 0.6145527124320642],\n",
    " [33.97772534368783, 0.6320702095720839],\n",
    " [77.21460416940018, 0.6251308878772128],\n",
    " [33.09577123018296, 0.6497419434149598],\n",
    " [75.7548104408701, 0.6150067375930129],\n",
    " [43.87491423384899, 0.6347928171275253],\n",
    " [10.126712078623463, 0.6163926151201515],\n",
    " [73.13222934491081, 0.6228855179798685],\n",
    " [13.298636964146718, 0.6319929658477089],\n",
    " [5.745541472548556, 0.5798983268186692],\n",
    " [51.07753369783381, 0.6310732582364519],\n",
    " [48.27039823204833, 0.608110557734599],\n",
    " [70.67036202963719, 0.6084508466852947],\n",
    " [11.911012833737168, 0.6171430064245845],\n",
    " [23.27205318710343, 0.6480115469432688],\n",
    " [74.65148756171158, 0.6063280883629821],\n",
    " [46.03975585418294, 0.6385532877511736],\n",
    " [88.73063334518115, 0.6157987552702076],\n",
    " [15.112014259630255, 0.632248639336992],\n",
    " [70.54701162674672, 0.6425789357114744],\n",
    " [66.62072575726674, 0.6220946065606155],\n",
    " [75.30990062793798, 0.6221431677132968],\n",
    " [45.764093483677726, 0.6093839039129627],\n",
    " [14.745069708180687, 0.6328860524732964],\n",
    " [37.74487976038759, 0.639881972005122],\n",
    " [62.92273159069691, 0.6317943579013554],\n",
    " [27.99221881307002, 0.6399269316884199],\n",
    " [97.87903638080532, 0.5967408998628895],\n",
    " [25.463424755488077, 0.6377285977028051],\n",
    " [57.83880021980526, 0.6297172460089651],\n",
    " [81.01585364947968, 0.6198450193944232],\n",
    " [29.61304667313932, 0.6563550659912724],\n",
    " [31.447579789710964, 0.632323242863966],\n",
    " [79.51186669719826, 0.6035403387860329],\n",
    " [46.89432075329132, 0.6414333683023186],\n",
    " [29.689344432140643, 0.6381816152027437]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>MRR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.550654</td>\n",
       "      <td>0.632089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89.703663</td>\n",
       "      <td>0.614657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.639934</td>\n",
       "      <td>0.654495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.043306</td>\n",
       "      <td>0.595821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.418462</td>\n",
       "      <td>0.630471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    features       MRR\n",
       "0  77.550654  0.632089\n",
       "1  89.703663  0.614657\n",
       "2  31.639934  0.654495\n",
       "3   7.043306  0.595821\n",
       "4  24.418462  0.630471"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = pd.DataFrame(array)\n",
    "metric.columns = ['features','MRR']\n",
    "metric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>MRR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>29.613047</td>\n",
       "      <td>0.656355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.639934</td>\n",
       "      <td>0.654495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>33.095771</td>\n",
       "      <td>0.649742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>24.439847</td>\n",
       "      <td>0.648020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>23.272053</td>\n",
       "      <td>0.648012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>25.335227</td>\n",
       "      <td>0.647120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>39.767434</td>\n",
       "      <td>0.645950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>37.568300</td>\n",
       "      <td>0.645565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>14.043403</td>\n",
       "      <td>0.645500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>21.477963</td>\n",
       "      <td>0.645059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     features       MRR\n",
       "95  29.613047  0.656355\n",
       "2   31.639934  0.654495\n",
       "67  33.095771  0.649742\n",
       "40  24.439847  0.648020\n",
       "78  23.272053  0.648012\n",
       "53  25.335227  0.647120\n",
       "31  39.767434  0.645950\n",
       "17  37.568300  0.645565\n",
       "48  14.043403  0.645500\n",
       "54  21.477963  0.645059"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.sort_values(by=['MRR'],ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.to_csv('metric_MRR.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
