{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www3.um.edu.uy/logoum.jpg\" width=300>\n",
    "    <h1 align=\"center\">Thesis - Alternating Least Squares hyperparameter optimization</h1> \n",
    "<h2 align=\"center\">Alejo Paullier</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "import flask\n",
    "import GPyOpt\n",
    "import sherpa\n",
    "import pylab as pl\n",
    "import time\n",
    "\n",
    "from lenskit import batch, topn, util\n",
    "from lenskit import crossfold as xf\n",
    "from lenskit.algorithms import Recommender, als\n",
    "from lenskit import topn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data & define evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('C:\\\\Users\\\\Alejo\\\\Tesis\\\\Demo\\\\ml-100k\\\\u.data', sep='\\t',\n",
    "                      names=['user', 'item', 'rating', 'timestamp'])\n",
    "\n",
    "\n",
    "def eval(aname, algo, train, test):\n",
    "    fittable = util.clone(algo) # Object cloning means to create an exact copy of the original object.\n",
    "    fittable = Recommender.adapt(fittable) \n",
    "    fittable.fit(train) # Entrenamos el algoritmo con el training dataset\n",
    "    users = test.user.unique() # Devuelve un array con los users unicos en el testing dataset\n",
    "    # now we run the recommender\n",
    "    recs = batch.recommend(fittable, users, 100)\n",
    "    # add the algorithm name for analyzability\n",
    "    recs['Algorithm'] = aname\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(feat):\n",
    "    all_recs = []\n",
    "    test_data = []\n",
    "    algo_als = als.BiasedMF(feat,iterations=20, reg=0.1, damping=5, bias=True, progress=None)\n",
    "    for train, test in xf.partition_users(ratings[['user', 'item', 'rating']], 1, xf.SampleFrac(0.2)):\n",
    "        test_data.append(test)\n",
    "        all_recs.append(eval('ALS', algo_als, train, test))\n",
    "    all_recs = pd.concat(all_recs, ignore_index=True)\n",
    "    all_recs.head()\n",
    "    test_data = pd.concat(test_data, ignore_index=True)\n",
    "    rla = topn.RecListAnalysis()\n",
    "    rla.add_metric(topn.ndcg)\n",
    "    results = rla.compute(all_recs, test_data)\n",
    "    results.head()\n",
    "    ndcg = results.groupby('Algorithm').ndcg.mean() \n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [sherpa.Discrete('feat', [1,20])]\n",
    "alg = sherpa.algorithms.RandomSearch(max_num_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = sherpa.Study(parameters=parameters,\n",
    "                     algorithm=alg,\n",
    "                     lower_is_better=False,\n",
    "                     disable_dashboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1:\t{'feat': 19}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3890551be1a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Trial {}:\\t{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel_trainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'feat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mnum_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "for trial in study:\n",
    "    print(\"Trial {}:\\t{}\".format(trial.id, trial.parameters))\n",
    "    model_trainer = models(trial.parameters['feat'])\n",
    "    num_iterations = 10\n",
    "    for iteration in range(num_iterations):\n",
    "        study.add_observation(trial=trial,\n",
    "                              iteration=iteration,\n",
    "                              objective=model_trainer)\n",
    "        time.sleep(0.1)\n",
    "    study.finalize(trial=trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(\"modules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### environment variable\n",
    "An environment variable is a key, value pair that is stored in computer memory and available to other programs running in the same environment. For example the PATH environment variable, is a key, value pair where the key is PATH and the value is a list of directories, such as /usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin. In particular, the shell uses the value of the PATH environment variable as a list of directories to search for executable programs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
