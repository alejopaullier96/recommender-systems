{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www3.um.edu.uy/logoum.jpg\" width=300>\n",
    "<h1 align=\"center\">Thesis - KNN Item Item RMSE</h1> \n",
    "<h2 align=\"center\">Alejo Paullier</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lkpy.lenskit.org/en/stable/knn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit import batch, topn, util\n",
    "from lenskit import crossfold as xf\n",
    "from lenskit.algorithms import Recommender, item_knn as knn\n",
    "from lenskit.metrics.predict import rmse\n",
    "from lenskit import topn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "ratings = pd.read_csv('C:\\\\Users\\\\Alejo\\\\Tesis\\\\Demo\\\\ml-100k\\\\u.data', sep='\\t',\n",
    "                      names=['user', 'item', 'rating', 'timestamp'])\n",
    "\n",
    "\n",
    "def eval(aname, algo, train, test):\n",
    "    fittable = util.clone(algo) # Object cloning means to create an exact copy of the original object.\n",
    "    fittable = Recommender.adapt(fittable) \n",
    "    fittable.fit(train) # Entrenamos el algoritmo con el training dataset\n",
    "    users = test.user.unique() # Devuelve un array con los users unicos en el testing dataset\n",
    "    # now we run the recommender\n",
    "    recs = batch.recommend(fittable, users, 100)\n",
    "    # add the algorithm name for analyzability\n",
    "    recs['Algorithm'] = aname\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_ii = knn.ItemItem(2,aggregate='weighted-average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train algorithm with some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lenskit.algorithms.item_knn.ItemItem at 0x19cb4307828>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_ii.fit(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>3.468619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>4.386858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>0.437298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>2.658149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>3.624622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating  timestamp  prediction\n",
       "0   196   242       3  881250949    3.468619\n",
       "1   186   302       3  891717742    4.386858\n",
       "2    22   377       1  878887116    0.437298\n",
       "3   244    51       2  880606923    2.658149\n",
       "4   166   346       1  886397596    3.624622"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = batch.predict(algo_ii, ratings)\n",
    "preds.head()\n",
    "\n",
    "# La columna \"prediction\" es una estimación de que rating le asignaría el usuario X al item Y dado el algoritmo\n",
    "# que se le pasa a \"batch.predict\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute per-user RMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8756399790479684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "user\n",
       "1    0.782914\n",
       "2    0.891713\n",
       "3    0.981827\n",
       "4    0.953156\n",
       "5    0.954410\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rmse = preds.groupby('user').apply(lambda df: rmse(df.prediction, df.rating))\n",
    "print(user_rmse.mean())\n",
    "user_rmse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8410757906739699"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(preds['prediction'], preds['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.301162633521313"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr = pd.DataFrame([[2,8],[4,5]])\n",
    "rmse(fr[0],fr[1])\n",
    "\n",
    "### Example: RMSE = sqrt( [(2-8)^2 + (4-5)^2]/2  ) = 4.301162633521313"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
